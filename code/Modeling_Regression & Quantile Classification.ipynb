{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.stattools import pacf, acf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.metrics import r2_score, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from mlxtend.classifier import StackingClassifier, EnsembleVoteClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_pickle(os.getcwd() + r'\\Data\\Intraday\\Pickle\\master.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPX_k1</th>\n",
       "      <th>SPX_k2</th>\n",
       "      <th>SPX_ImpVol1</th>\n",
       "      <th>SPX_ImpVol2</th>\n",
       "      <th>DaysTo_VX1_Expiry</th>\n",
       "      <th>DaysTo_VX2_Expiry</th>\n",
       "      <th>VX1_Future</th>\n",
       "      <th>OPT</th>\n",
       "      <th>VX1-OPT_Spread</th>\n",
       "      <th>VIX_ImpVol</th>\n",
       "      <th>SPX_Index(fwd)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02 09:40:00</th>\n",
       "      <td>2070.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>11.9931</td>\n",
       "      <td>32.9931</td>\n",
       "      <td>17.175</td>\n",
       "      <td>13.9409</td>\n",
       "      <td>3.2341</td>\n",
       "      <td>1.1445</td>\n",
       "      <td>2072.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 09:50:00</th>\n",
       "      <td>2070.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>0.1325</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>11.9861</td>\n",
       "      <td>32.9861</td>\n",
       "      <td>17.275</td>\n",
       "      <td>13.8315</td>\n",
       "      <td>3.4435</td>\n",
       "      <td>1.1405</td>\n",
       "      <td>2068.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 10:00:00</th>\n",
       "      <td>2070.0</td>\n",
       "      <td>2065.0</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>11.9792</td>\n",
       "      <td>32.9792</td>\n",
       "      <td>17.375</td>\n",
       "      <td>14.0993</td>\n",
       "      <td>3.2757</td>\n",
       "      <td>1.1428</td>\n",
       "      <td>2068.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 10:10:00</th>\n",
       "      <td>2065.0</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>11.9722</td>\n",
       "      <td>32.9722</td>\n",
       "      <td>17.725</td>\n",
       "      <td>14.6378</td>\n",
       "      <td>3.0872</td>\n",
       "      <td>1.1837</td>\n",
       "      <td>2063.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 10:20:00</th>\n",
       "      <td>2065.0</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>11.9653</td>\n",
       "      <td>32.9653</td>\n",
       "      <td>17.725</td>\n",
       "      <td>14.7280</td>\n",
       "      <td>2.9970</td>\n",
       "      <td>1.1836</td>\n",
       "      <td>2063.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SPX_k1  SPX_k2  SPX_ImpVol1  SPX_ImpVol2  \\\n",
       "2015-01-02 09:40:00  2070.0  2070.0       0.1326       0.1370   \n",
       "2015-01-02 09:50:00  2070.0  2070.0       0.1325       0.1362   \n",
       "2015-01-02 10:00:00  2070.0  2065.0       0.1343       0.1386   \n",
       "2015-01-02 10:10:00  2065.0  2060.0       0.1397       0.1440   \n",
       "2015-01-02 10:20:00  2065.0  2060.0       0.1407       0.1449   \n",
       "\n",
       "                     DaysTo_VX1_Expiry  DaysTo_VX2_Expiry  VX1_Future  \\\n",
       "2015-01-02 09:40:00            11.9931            32.9931      17.175   \n",
       "2015-01-02 09:50:00            11.9861            32.9861      17.275   \n",
       "2015-01-02 10:00:00            11.9792            32.9792      17.375   \n",
       "2015-01-02 10:10:00            11.9722            32.9722      17.725   \n",
       "2015-01-02 10:20:00            11.9653            32.9653      17.725   \n",
       "\n",
       "                         OPT  VX1-OPT_Spread  VIX_ImpVol  SPX_Index(fwd)  \n",
       "2015-01-02 09:40:00  13.9409          3.2341      1.1445         2072.15  \n",
       "2015-01-02 09:50:00  13.8315          3.4435      1.1405         2068.86  \n",
       "2015-01-02 10:00:00  14.0993          3.2757      1.1428         2068.50  \n",
       "2015-01-02 10:10:00  14.6378          3.0872      1.1837         2063.32  \n",
       "2015-01-02 10:20:00  14.7280          2.9970      1.1836         2063.04  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a7e392b0f0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAFGCAYAAABuaDhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a7e3922630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#master.corr().iloc[:,6].plot(kind='bar')\n",
    "master.iloc[:,6:15].corr().iloc[:,0].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take log returns for every feature EXCEPT $VX1-OPT$ Spread "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "master[['Ratio', 'OPT_Ratio','VIX_ImpVol_Ratio', 'SPX_Index(fwd)_Ratio']] = \\\n",
    "        np.log(master[['VX1_Future', 'OPT','VIX_ImpVol', 'SPX_Index(fwd)']]/ \\\n",
    "               master[['VX1_Future', 'OPT','VIX_ImpVol', 'SPX_Index(fwd)']].shift(1))\n",
    "master.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a7e393cb00>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAFeCAYAAACB7binAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIrokMURERJckhoiI6JLEEBERXf4/lQXcoiUgBnAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a7e3976668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master.corr().loc[:,'Ratio'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20249, 15)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide dataset into 75/25 (%) Train/Test Split, Scale features for zero mean & unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15186, 15)\n",
      "(5063, 15)\n"
     ]
    }
   ],
   "source": [
    "nTrain = int(.75*master.shape[0])\n",
    "train, test = master[0:nTrain], master[nTrain:master.shape[0]]\n",
    "\n",
    "train.is_copy = False\n",
    "test.is_copy = False\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "columns = ['Ratio', 'OPT_Ratio', 'VX1-OPT_Spread','VIX_ImpVol_Ratio', 'SPX_Index(fwd)_Ratio']\n",
    "\n",
    "feature_cols = list(set(columns))\n",
    "\n",
    "for col in feature_cols:    \n",
    "    scl = StandardScaler()\n",
    "    train[col] = scl.fit_transform(train[col].as_matrix().reshape(-1,1))\n",
    "    test[col] = scl.transform(test[col].as_matrix().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPX_k1</th>\n",
       "      <th>SPX_k2</th>\n",
       "      <th>SPX_ImpVol1</th>\n",
       "      <th>SPX_ImpVol2</th>\n",
       "      <th>DaysTo_VX1_Expiry</th>\n",
       "      <th>DaysTo_VX2_Expiry</th>\n",
       "      <th>VX1_Future</th>\n",
       "      <th>OPT</th>\n",
       "      <th>VX1-OPT_Spread</th>\n",
       "      <th>VIX_ImpVol</th>\n",
       "      <th>SPX_Index(fwd)</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>OPT_Ratio</th>\n",
       "      <th>VIX_ImpVol_Ratio</th>\n",
       "      <th>SPX_Index(fwd)_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-07 13:10:00</th>\n",
       "      <td>2095.0</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>8.8472</td>\n",
       "      <td>30.8472</td>\n",
       "      <td>16.650</td>\n",
       "      <td>13.6492</td>\n",
       "      <td>0.441010</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>2093.79</td>\n",
       "      <td>0.166924</td>\n",
       "      <td>0.181305</td>\n",
       "      <td>0.328082</td>\n",
       "      <td>-0.013583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-07 13:20:00</th>\n",
       "      <td>2095.0</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>8.8403</td>\n",
       "      <td>30.8403</td>\n",
       "      <td>16.575</td>\n",
       "      <td>13.6150</td>\n",
       "      <td>0.382797</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>2094.69</td>\n",
       "      <td>-0.500575</td>\n",
       "      <td>-0.162103</td>\n",
       "      <td>0.462253</td>\n",
       "      <td>0.294499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-07 13:30:00</th>\n",
       "      <td>2095.0</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>0.1239</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>8.8333</td>\n",
       "      <td>30.8333</td>\n",
       "      <td>16.625</td>\n",
       "      <td>13.2552</td>\n",
       "      <td>0.967492</td>\n",
       "      <td>0.9556</td>\n",
       "      <td>2095.67</td>\n",
       "      <td>0.334364</td>\n",
       "      <td>-1.731500</td>\n",
       "      <td>0.018753</td>\n",
       "      <td>0.320574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-07 13:40:00</th>\n",
       "      <td>2095.0</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>8.8264</td>\n",
       "      <td>30.8264</td>\n",
       "      <td>16.525</td>\n",
       "      <td>13.2202</td>\n",
       "      <td>0.874751</td>\n",
       "      <td>0.9449</td>\n",
       "      <td>2096.43</td>\n",
       "      <td>-0.669024</td>\n",
       "      <td>-0.170843</td>\n",
       "      <td>-0.488490</td>\n",
       "      <td>0.248400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-07 13:50:00</th>\n",
       "      <td>2095.0</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>8.8194</td>\n",
       "      <td>30.8194</td>\n",
       "      <td>16.575</td>\n",
       "      <td>13.5602</td>\n",
       "      <td>0.460984</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>2094.54</td>\n",
       "      <td>0.335374</td>\n",
       "      <td>1.641889</td>\n",
       "      <td>0.321137</td>\n",
       "      <td>-0.619538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SPX_k1  SPX_k2  SPX_ImpVol1  SPX_ImpVol2  \\\n",
       "2016-07-07 13:10:00  2095.0  2090.0       0.1247       0.1332   \n",
       "2016-07-07 13:20:00  2095.0  2090.0       0.1247       0.1330   \n",
       "2016-07-07 13:30:00  2095.0  2095.0       0.1239       0.1301   \n",
       "2016-07-07 13:40:00  2095.0  2095.0       0.1235       0.1298   \n",
       "2016-07-07 13:50:00  2095.0  2090.0       0.1240       0.1324   \n",
       "\n",
       "                     DaysTo_VX1_Expiry  DaysTo_VX2_Expiry  VX1_Future  \\\n",
       "2016-07-07 13:10:00             8.8472            30.8472      16.650   \n",
       "2016-07-07 13:20:00             8.8403            30.8403      16.575   \n",
       "2016-07-07 13:30:00             8.8333            30.8333      16.625   \n",
       "2016-07-07 13:40:00             8.8264            30.8264      16.525   \n",
       "2016-07-07 13:50:00             8.8194            30.8194      16.575   \n",
       "\n",
       "                         OPT  VX1-OPT_Spread  VIX_ImpVol  SPX_Index(fwd)  \\\n",
       "2016-07-07 13:10:00  13.6492        0.441010      0.9451         2093.79   \n",
       "2016-07-07 13:20:00  13.6150        0.382797      0.9552         2094.69   \n",
       "2016-07-07 13:30:00  13.2552        0.967492      0.9556         2095.67   \n",
       "2016-07-07 13:40:00  13.2202        0.874751      0.9449         2096.43   \n",
       "2016-07-07 13:50:00  13.5602        0.460984      0.9519         2094.54   \n",
       "\n",
       "                        Ratio  OPT_Ratio  VIX_ImpVol_Ratio  \\\n",
       "2016-07-07 13:10:00  0.166924   0.181305          0.328082   \n",
       "2016-07-07 13:20:00 -0.500575  -0.162103          0.462253   \n",
       "2016-07-07 13:30:00  0.334364  -1.731500          0.018753   \n",
       "2016-07-07 13:40:00 -0.669024  -0.170843         -0.488490   \n",
       "2016-07-07 13:50:00  0.335374   1.641889          0.321137   \n",
       "\n",
       "                     SPX_Index(fwd)_Ratio  \n",
       "2016-07-07 13:10:00             -0.013583  \n",
       "2016-07-07 13:20:00              0.294499  \n",
       "2016-07-07 13:30:00              0.320574  \n",
       "2016-07-07 13:40:00              0.248400  \n",
       "2016-07-07 13:50:00             -0.619538  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define x, y variables for Train & Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (15176, 50)\n",
      "x_test:  (5053, 50)\n"
     ]
    }
   ],
   "source": [
    "nlags = 10\n",
    "\n",
    "# CALCULATE TRAINING SET\n",
    "y_train = train.loc[:,'Ratio'].values[nlags:]\n",
    "x_train = train.loc[:,['Ratio','OPT_Ratio', 'VX1-OPT_Spread','VIX_ImpVol_Ratio',\\\n",
    "                              'SPX_Index(fwd)_Ratio']].shift(1).values[nlags:]\n",
    "for i in range(2,nlags+1):\n",
    "    lagged_train = train.loc[:,['Ratio', 'OPT_Ratio', 'VX1-OPT_Spread','VIX_ImpVol_Ratio',\\\n",
    "                           'SPX_Index(fwd)_Ratio']].shift(i).values[nlags:]\n",
    "    x_train = np.concatenate((x_train, lagged_train), axis=1)\n",
    "\n",
    "print('x_train: ',x_train.shape)\n",
    "\n",
    "# CALCULATE TEST SET\n",
    "y_test = test.loc[:,'Ratio'].values[nlags:]\n",
    "x_test = test.loc[:,['Ratio','OPT_Ratio', 'VX1-OPT_Spread','VIX_ImpVol_Ratio',\\\n",
    "                              'SPX_Index(fwd)_Ratio']].shift(1).values[nlags:]\n",
    "for i in range(2,nlags+1):\n",
    "    lagged_test = test.loc[:,['Ratio', 'OPT_Ratio', 'VX1-OPT_Spread','VIX_ImpVol_Ratio',\\\n",
    "                           'SPX_Index(fwd)_Ratio']].shift(i).values[nlags:]\n",
    "    x_test = np.concatenate((x_test, lagged_test), axis=1)\n",
    "\n",
    "print('x_test: ',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00927613809245\n"
     ]
    }
   ],
   "source": [
    "r1 = lr.score(x_test, y_test)\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "           oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators=200, max_depth=5, n_jobs=-1, random_state=1)\n",
    "rf_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00447850260808\n"
     ]
    }
   ],
   "source": [
    "r2 = rf_reg.score(x_test,y_test)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.05, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=200, presort='auto', random_state=None,\n",
       "             subsample=0.5, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor(learning_rate=0.05, subsample=0.5, max_depth=3, n_estimators=200)\n",
    "gb_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0237727429274\n"
     ]
    }
   ],
   "source": [
    "r3 = gb_reg.score(x_test,y_test)\n",
    "print(r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009276</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.023773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Linear Regression  Random Forest  Gradient Boosting\n",
       "0          -0.009276       0.004479           0.023773"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Linear Regression': [r1], 'Random Forest': [r2], 'Gradient Boosting': [r3]}\n",
    "regress = pd.DataFrame(data=d, columns=['Linear Regression', 'Random Forest', 'Gradient Boosting']) \n",
    "regress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quartile Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-16.181530948174878,\n",
       " -0.3695287618184102,\n",
       " 0.00023774935829143294,\n",
       " 0.3580762875300375,\n",
       " 28.696159238409937]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = master['Ratio'].quantile(np.arange(0,1.1,.25)).values.tolist()\n",
    "bins[0] -= 1\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['class'] = pd.cut(master['Ratio'], bins=bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    8140\n",
      "0    5065\n",
      "3    5058\n",
      "2    1986\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "vc = master['class'].value_counts()\n",
    "print(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(-15.1815, -0.3695)</th>\n",
       "      <th>(-0.3695, 0.0002)</th>\n",
       "      <th>(0.0002, 0.3581)</th>\n",
       "      <th>(0.3581, 28.6962)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5065</td>\n",
       "      <td>8140</td>\n",
       "      <td>1986</td>\n",
       "      <td>5058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (-15.1815, -0.3695)  (-0.3695, 0.0002)  (0.0002, 0.3581)  (0.3581, 28.6962)\n",
       "0                 5065               8140              1986               5058"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = round(bins[0]+1,4),round(bins[1],4)\n",
    "c2 = round(bins[1],4),round(bins[2],4)\n",
    "c3 = round(bins[2],4),round(bins[3],4)\n",
    "c4 = round(bins[3],4),round(bins[4],4)\n",
    "d2 = {c1: [vc[0]], c2: [vc[1]], c3: [vc[2]], c4: [vc[3]]}\n",
    "#print(c1)\n",
    "quarts = pd.DataFrame(data=d2, columns=[c1, c2, c3, c4])\n",
    "quarts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide dataset into 75/25 (%) Train/Test Split, Scale features for zero mean & unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15186, 16)\n",
      "(5063, 16)\n"
     ]
    }
   ],
   "source": [
    "nTrain = int(.75*master.shape[0])\n",
    "train, test = master[0:nTrain], master[nTrain:master.shape[0]]\n",
    "\n",
    "train.is_copy = False\n",
    "test.is_copy = False\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "columns = ['Ratio', 'OPT_Ratio', 'VX1-OPT_Spread','VIX_ImpVol_Ratio', 'SPX_Index(fwd)_Ratio']\n",
    "\n",
    "feature_cols = list(set(columns))\n",
    "\n",
    "for col in feature_cols:    \n",
    "    scl = StandardScaler()\n",
    "    train[col] = scl.fit_transform(train[col].as_matrix().reshape(-1,1))\n",
    "    test[col] = scl.transform(test[col].as_matrix().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define x, y variables for Train & Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (15176, 50)\n",
      "x_test:  (5053, 50)\n"
     ]
    }
   ],
   "source": [
    "nlags = 10\n",
    "\n",
    "# CALCULATE TRAINING SET\n",
    "y_train = train.loc[:,'class'].values[nlags:]\n",
    "x_train = train.loc[:,['Ratio','OPT_Ratio', 'VX1-OPT_Spread','VIX_ImpVol_Ratio',\\\n",
    "                              'SPX_Index(fwd)_Ratio']].shift(1).values[nlags:]\n",
    "for i in range(2,nlags+1):\n",
    "    lagged_train = train.loc[:,['Ratio', 'OPT_Ratio', 'VX1-OPT_Spread','VIX_ImpVol_Ratio',\\\n",
    "                           'SPX_Index(fwd)_Ratio']].shift(i).values[nlags:]\n",
    "    x_train = np.concatenate((x_train, lagged_train), axis=1)\n",
    "\n",
    "print('x_train: ',x_train.shape)\n",
    "\n",
    "# CALCULATE TEST SET\n",
    "y_test = test.loc[:,'class'].values[nlags:]\n",
    "x_test = test.loc[:,['Ratio','OPT_Ratio', 'VX1-OPT_Spread','VIX_ImpVol_Ratio',\\\n",
    "                              'SPX_Index(fwd)_Ratio']].shift(1).values[nlags:]\n",
    "for i in range(2,nlags+1):\n",
    "    lagged_test = test.loc[:,['Ratio', 'OPT_Ratio', 'VX1-OPT_Spread','VIX_ImpVol_Ratio',\\\n",
    "                           'SPX_Index(fwd)_Ratio']].shift(i).values[nlags:]\n",
    "    x_test = np.concatenate((x_test, lagged_test), axis=1)\n",
    "\n",
    "print('x_test: ',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=7)\n",
    "KNN.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=7)\n",
    "KNN.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40332475757\n"
     ]
    }
   ],
   "source": [
    "cl1 = KNN.score(x_test, y_test)\n",
    "print(cl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200, max_depth=5, n_jobs=-1, criterion='entropy', random_state=1)\n",
    "rfc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.446467445082\n"
     ]
    }
   ],
   "source": [
    "cl2 = rfc.score(x_test,y_test)\n",
    "print(cl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.05, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              presort='auto', random_state=None, subsample=0.5, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=3, n_estimators=200)\n",
    "gbc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.460716406095\n"
     ]
    }
   ],
   "source": [
    "cl3 = gbc.score(x_test,y_test)\n",
    "print(cl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Stacking ('Wisdom of the Crowd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45 [RandomForest_gini]\n",
      "Accuracy: 0.45 [RandomForest_entropy]\n",
      "Accuracy: 0.45 [AdaBoostClassifier]\n",
      "Accuracy: 0.46 [GradientBoostingClassifier]\n",
      "Accuracy: 0.46 [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "# STACK Models\n",
    "clf1 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf2 = RandomForestClassifier(n_estimators=200, max_depth=5, n_jobs=1, criterion='gini', random_state=1)\n",
    "clf3 = RandomForestClassifier(n_estimators=200, max_depth=5, n_jobs=1, criterion='entropy', random_state=1)\n",
    "clf4 = AdaBoostClassifier(n_estimators=200)\n",
    "clf5 = GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=3, n_estimators=200)\n",
    "#sclf = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4],\n",
    "sclf = StackingClassifier(classifiers=[clf2, clf3, clf4, clf5],\n",
    "                          use_probas=False,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=clf4)\n",
    "\n",
    "#for clf, label in zip([clf1, clf2, clf3, clf4, clf5, sclf],\n",
    "for clf, label in zip([clf2, clf3, clf4, clf5, sclf],\n",
    "                      [#'KNN',\n",
    "                       'RandomForest_gini',\n",
    "                       'RandomForest_entropy',\n",
    "                       'AdaBoostClassifier',\n",
    "                       'GradientBoostingClassifier',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    print(\"Accuracy: %0.2f [%s]\" % (clf.fit(x_train, y_train).score(x_test, y_test), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44765485849990105"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4], weights=[1, 1, 1, 2], voting='soft')\n",
    "eclf.fit(x_train, y_train).score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.460914308332\n"
     ]
    }
   ],
   "source": [
    "sclf = StackingClassifier(classifiers=[clf2, clf3, clf4, clf5],\n",
    "                          use_probas=False,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=clf4)\n",
    "cl4 = sclf.fit(x_train, y_train).score(x_test, y_test)\n",
    "print(cl4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45477933900653078"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf = EnsembleVoteClassifier(clfs=[clf2, clf3, clf4, clf5], weights=[1, 1, 1, 2], voting='soft')\n",
    "eclf.fit(x_train, y_train).score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNeighbors (KNN)</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>Stacking Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.403325</td>\n",
       "      <td>0.446467</td>\n",
       "      <td>0.460716</td>\n",
       "      <td>0.460914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   KNeighbors (KNN)  Random Forest  Gradient Boosting  Stacking Classifier\n",
       "0          0.403325       0.446467           0.460716             0.460914"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = {'KNeighbors (KNN)': [cl1], 'Random Forest': [cl2], 'Gradient Boosting': [cl3], 'Stacking Classifier': [cl4]}\n",
    "classify = pd.DataFrame(data=d3, columns=['KNeighbors (KNN)', 'Random Forest', 'Gradient Boosting', 'Stacking Classifier']) \n",
    "classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
